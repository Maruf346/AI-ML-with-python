{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruf346/AI-ML-with-python/blob/main/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Iris Dataset Classification**\n",
        "The Iris dataset is a popular dataset in machine learning, consisting of 150 samples of iris flowers, each\n",
        "with four features (sepal length, sepal width, petal length, and petal width) and a target variable specifying\n",
        "the type of iris (Setosa, Versicolour, or Virginica)."
      ],
      "metadata": {
        "id": "oF_RR7OUuWY_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q72AU00jAvnI",
        "outputId": "987639b8-38dd-42c9-f805-a038feea8838"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted target values: [0 1 1 0 0 1 2 1 1 2 2 1 1 1 2 0 1 2 0 2 1 0 1 1 0 0 2 2 2 1 0 2 1 2 0 0 2\n",
            " 0 0 1 2 0 0 1 2]\n",
            "Actual target values: [0 1 1 0 0 1 2 1 1 2 2 1 1 1 2 0 1 2 0 2 1 0 1 1 0 0 2 2 2 1 0 2 1 2 0 0 2\n",
            " 0 0 1 2 0 0 1 2]\n",
            "Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# load the iris dataset\n",
        "iris = load_iris ()\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train , X_test , y_train , y_test = train_test_split(iris.data ,\n",
        "iris.target , test_size =0.3, random_state =15)\n",
        "\n",
        "# create a logistic regression model\n",
        "log_reg = LogisticRegression ()\n",
        "\n",
        "# fit the model on the training data\n",
        "log_reg.fit(X_train , y_train)\n",
        "\n",
        "# make predictions on the testing data\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test , y_pred)\n",
        "\n",
        "#print(iris.data)\n",
        "#print(iris.target)\n",
        "print(\"Predicted target values:\", y_pred)\n",
        "print(\"Actual target values:\", y_test)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Logistic Regression on Iris dataset using Sepal Length vs Petal Width only.**"
      ],
      "metadata": {
        "id": "TVI9dr_YIUs-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.preprocessing import StandardSc\n",
        "\n",
        "# Load the iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data[:, [0, 3]]  # Only Sepal Length and Petal Width\n",
        "y = iris.target\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.7, random_state=15\n",
        ")\n",
        "\n",
        "# Scaling - Preprocessing...\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Train logistic regression model\n",
        "log_reg = LogisticRegression()\n",
        "log_reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict\n",
        "y_pred = log_reg.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "# Output\n",
        "print(\"Predicted target values:\", y_pred)\n",
        "print(\"\\nActual target values:\", y_test)\n",
        "print(\"\\nAccuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KXsAN6QmIhf1",
        "outputId": "5b8818df-e759-448b-8613-9a15a1317f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted target values: [0 1 1 0 0 1 2 0 1 2 2 1 1 1 2 0 1 2 0 2 1 0 1 0 0 0 2 2 2 1 0 2 1 2 0 0 2\n",
            " 0 0 1 2 0 0 1 2 2 0 1 0 2 2 2 2 1 1 1 0 1 2 2 2 2 0 1 1 2 2 0 1 0 0 2 1 1\n",
            " 1 1 0 2 2 2 0 2 0 0 2 2 1 1 2 0 0 0 1 1 1 0 2 0 1 0 0 0 2 2 2]\n",
            "\n",
            "Actual target values: [0 1 1 0 0 1 2 1 1 2 2 1 1 1 2 0 1 2 0 2 1 0 1 1 0 0 2 2 2 1 0 2 1 2 0 0 2\n",
            " 0 0 1 2 0 0 1 2 2 0 1 0 2 2 2 2 1 1 1 0 1 2 2 2 2 0 2 1 2 1 0 1 0 0 2 1 1\n",
            " 1 1 0 2 2 2 0 1 0 0 2 2 1 1 2 1 0 0 1 1 1 0 2 0 1 0 1 0 2 2 2]\n",
            "\n",
            "Accuracy: 0.9333333333333333\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Implement logistic regression from scratch (i.e., without using any machine learning library) and compare the performance with the one of scikit-learn.**"
      ],
      "metadata": {
        "id": "OfFShMEpJ58v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load full Iris dataset (all 4 features)\n",
        "iris = load_iris()\n",
        "X = iris.data        # All features\n",
        "y = iris.target      # Target labels\n",
        "\n",
        "# Train/test split (70% test set)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.7, random_state=50\n",
        ")\n",
        "\n",
        "# Scaling - Preprocessing...\n",
        "scaler = StandardScaler()\n",
        "X_train_std = scaler.fit_transform(X_train)\n",
        "X_test_std = scaler.transform(X_test)\n",
        "\n",
        "# ========== Logistic Regression from Scratch ==========\n",
        "\n",
        "def softmax(z):\n",
        "    exp_z = np.exp(z - np.max(z, axis=1, keepdims=True))\n",
        "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
        "\n",
        "def train_softmax(X, y, lr=0.1, n_iter=4000):\n",
        "  # Add bias (intercept) column\n",
        "    Xb = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "\n",
        "    n_samples, n_features = Xb.shape\n",
        "    n_classes = np.unique(y).size\n",
        "\n",
        "    W = np.zeros((n_classes, n_features))  #weight\n",
        "    y_onehot = np.eye(n_classes)[y]        #One-hot encoding...\n",
        "\n",
        "    # Gradient Descent\n",
        "    for _ in range(n_iter):\n",
        "        scores = Xb @ W.T\n",
        "        probs = softmax(scores)\n",
        "        gradient = (probs - y_onehot).T @ Xb / n_samples\n",
        "        W -= lr * gradient\n",
        "    return W\n",
        "\n",
        "def predict_softmax(X, W):\n",
        "    Xb = np.hstack([np.ones((X.shape[0], 1)), X])\n",
        "    scores = Xb @ W.T\n",
        "    probs = softmax(scores)\n",
        "    return np.argmax(probs, axis=1)\n",
        "\n",
        "# Train scratch model\n",
        "W = train_softmax(X_train_std, y_train)\n",
        "y_pred_scratch = predict_softmax(X_test_std, W)\n",
        "acc_scratch = accuracy_score(y_test, y_pred_scratch)\n",
        "\n",
        "# ========== scikit-learn Logistic Regression ==========\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train_std, y_train)\n",
        "y_pred_sklearn = model.predict(X_test_std)\n",
        "acc_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
        "\n",
        "# ========== Results ==========\n",
        "print(f\"Scratch model accuracy      : {acc_scratch:.6f}\")\n",
        "print(f\"scikit-learn model accuracy : {acc_sklearn:.6f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3SNl8VfKEAm",
        "outputId": "54a907ac-ce9b-43c8-95d1-374d6460d99c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scratch model accuracy      : 0.952381\n",
            "scikit-learn model accuracy : 0.961905\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Another approach: Implement logistic regression from scratch (i.e., without using any machine learning library) and compare the performance with the one of scikit-learn.**"
      ],
      "metadata": {
        "id": "xNesKZf1l1cv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def sigmoid(z):\n",
        "    return 1 / (1 + np.exp(-z))\n",
        "\n",
        "def predict(X, weights):\n",
        "    z = np.dot(X, weights)\n",
        "    return sigmoid(z)\n",
        "\n",
        "def compute_cost(X, y, weights):\n",
        "    m = len(y)\n",
        "    h = predict(X, weights)\n",
        "    cost = (-1/m) * np.sum(y*np.log(h) + (1-y)*np.log(1 - h))\n",
        "    return cost\n",
        "\n",
        "def gradient_descent(X, y, weights, lr, iterations):\n",
        "    m = len(y)\n",
        "    for _ in range(iterations):\n",
        "        h = predict(X, weights)\n",
        "        gradient = np.dot(X.T, (h - y)) / m\n",
        "        weights -= lr * gradient\n",
        "    return weights\n",
        "\n",
        "# Load Iris\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "\n",
        "# Only keep 2 classes and 2 features\n",
        "X = iris.data[:, [0, 3]]  # Sepal length and petal width\n",
        "y = iris.target\n",
        "mask = y < 2\n",
        "X = X[mask]\n",
        "y = y[mask]\n",
        "\n",
        "# Normalize\n",
        "X = (X - np.mean(X, axis=0)) / np.std(X, axis=0)\n",
        "\n",
        "# Add bias\n",
        "X = np.hstack((np.ones((X.shape[0], 1)), X))\n",
        "y = y.reshape(-1, 1)\n",
        "\n",
        "# Initialize weights and run GD\n",
        "weights = np.zeros((X.shape[1], 1))\n",
        "weights = gradient_descent(X, y, weights, lr=0.1, iterations=1000)\n",
        "\n",
        "# Predict and evaluate\n",
        "preds = predict(X, weights)\n",
        "preds = (preds >= 0.5).astype(int)\n",
        "acc = np.mean(preds == y)\n",
        "print(\"Scratch model accuracy:\", acc)\n",
        "\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "X_sklearn = iris.data[mask][:, [0, 3]]\n",
        "y_sklearn = iris.target[mask]\n",
        "\n",
        "model = LogisticRegression()\n",
        "model.fit(X_sklearn, y_sklearn)\n",
        "preds = model.predict(X_sklearn)\n",
        "print(\"Scikit-learn model accuracy:\", accuracy_score(y_sklearn, preds))\n"
      ],
      "metadata": {
        "id": "uwQB8j_Pl_Sr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8715b3d7-6ae1-4af4-aa75-e14dc24e3f15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scratch model accuracy: 1.0\n",
            "Scikit-learn model accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}