{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUhrngJSvlnDSPNQ0v2h+7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Maruf346/AI-ML-with-python/blob/main/Preprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use the dataset and apply all necessary data preprocessing techniques to prepare the dataset for machine learning models. This includes handling missing values, scaling, encoding categorical variables (if any), and any other relevant preprocessing steps.**"
      ],
      "metadata": {
        "id": "OBgQ-uPtlyN-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIdRbnp1luOW",
        "outputId": "df3e54aa-7778-4081-d67b-947456ccf06a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Shape: (1000, 13)\n",
            "\n",
            "Preview of dataset:\n",
            "   Employee_ID Employee_Name    Age      Salary  Years_at_Company  \\\n",
            "0      E00001   Alex Miller  150.0  2000000.00              29.0   \n",
            "1      E00002    Alex Smith  200.0  1500000.00              37.0   \n",
            "2      E00003   Jane Garcia    5.0  1200000.00               3.0   \n",
            "3      E00004   Emily Brown  200.0    23118.19              42.0   \n",
            "4      E00005    Mike Jones  150.0    20852.42              33.0   \n",
            "\n",
            "   Number_of_Projects  Performance_Score  Is_Manager  Works_Remotely  \\\n",
            "0                 2.0                3.0           0             0.0   \n",
            "1                 7.0                3.0           0             0.0   \n",
            "2                 3.0                3.0           0             0.0   \n",
            "3                 7.0                3.0           1             0.0   \n",
            "4                 2.0                5.0           0             0.0   \n",
            "\n",
            "    Department Education_Level Location                   Hire_Date  \n",
            "0    marketing             PHD   AUSTIN  2023-11-02 20:17:14.115619  \n",
            "1  Engineering      Highschool   BOSTON  2024-11-21 20:17:14.115619  \n",
            "2        Sales             PHD   AUSTIN  2022-11-30 20:17:14.115619  \n",
            "3           it      HIGHSCHOOL   Boston  2024-01-04 20:17:14.115619  \n",
            "4    Marketing      HIGHSCHOOL  SEATTLE  2018-05-11 20:17:14.115619  \n",
            "\n",
            "Missing values count:\n",
            " Employee_ID            0\n",
            "Employee_Name          0\n",
            "Age                   30\n",
            "Salary                40\n",
            "Years_at_Company      60\n",
            "Number_of_Projects    25\n",
            "Performance_Score     20\n",
            "Is_Manager             0\n",
            "Works_Remotely        25\n",
            "Department            30\n",
            "Education_Level       25\n",
            "Location              20\n",
            "Hire_Date             30\n",
            "dtype: int64\n",
            "\n",
            "Data types:\n",
            " Employee_ID            object\n",
            "Employee_Name          object\n",
            "Age                   float64\n",
            "Salary                float64\n",
            "Years_at_Company      float64\n",
            "Number_of_Projects    float64\n",
            "Performance_Score     float64\n",
            "Is_Manager              int64\n",
            "Works_Remotely        float64\n",
            "Department             object\n",
            "Education_Level        object\n",
            "Location               object\n",
            "Hire_Date              object\n",
            "dtype: object\n",
            "\n",
            "Numerical columns: ['Age', 'Salary', 'Years_at_Company', 'Number_of_Projects', 'Performance_Score', 'Is_Manager', 'Works_Remotely']\n",
            "Categorical columns: ['Employee_ID', 'Employee_Name', 'Department', 'Education_Level', 'Location', 'Hire_Date']\n",
            "\n",
            "Processed Dataset Shape: (1000, 1952)\n",
            "\n",
            "Preview of processed dataset:\n",
            "          Age     Salary  Years_at_Company  Number_of_Projects  \\\n",
            "0   9.829986  22.953674          7.055649            0.989425   \n",
            "1  13.106648  17.215256          9.002035            3.462987   \n",
            "2   0.327666  13.772204          0.729895            1.484137   \n",
            "3  13.106648   0.265324         10.218526            3.462987   \n",
            "4   9.829986   0.239320          8.028842            0.989425   \n",
            "\n",
            "   Performance_Score  Is_Manager  Works_Remotely  Employee_ID_E00001  \\\n",
            "0           2.706200    0.000000             0.0             31.6386   \n",
            "1           2.706200    0.000000             0.0              0.0000   \n",
            "2           2.706200    0.000000             0.0              0.0000   \n",
            "3           2.706200    2.468188             0.0              0.0000   \n",
            "4           4.510334    0.000000             0.0              0.0000   \n",
            "\n",
            "   Employee_ID_E00002  Employee_ID_E00003  ...  \\\n",
            "0              0.0000              0.0000  ...   \n",
            "1             31.6386              0.0000  ...   \n",
            "2              0.0000             31.6386  ...   \n",
            "3              0.0000              0.0000  ...   \n",
            "4              0.0000              0.0000  ...   \n",
            "\n",
            "   Hire_Date_2025-06-23 20:17:14.115619  Hire_Date_2025-06-25 20:17:14.115619  \\\n",
            "0                                   0.0                                   0.0   \n",
            "1                                   0.0                                   0.0   \n",
            "2                                   0.0                                   0.0   \n",
            "3                                   0.0                                   0.0   \n",
            "4                                   0.0                                   0.0   \n",
            "\n",
            "   Hire_Date_2025-06-28 20:17:14.115619  Hire_Date_2025-07-03 20:17:14.115619  \\\n",
            "0                                   0.0                                   0.0   \n",
            "1                                   0.0                                   0.0   \n",
            "2                                   0.0                                   0.0   \n",
            "3                                   0.0                                   0.0   \n",
            "4                                   0.0                                   0.0   \n",
            "\n",
            "   Hire_Date_2025-07-06 20:17:14.115619  Hire_Date_2025-07-10 20:17:14.115619  \\\n",
            "0                                   0.0                                   0.0   \n",
            "1                                   0.0                                   0.0   \n",
            "2                                   0.0                                   0.0   \n",
            "3                                   0.0                                   0.0   \n",
            "4                                   0.0                                   0.0   \n",
            "\n",
            "   Hire_Date_2025-07-11 20:17:14.115619  Hire_Date_2025-07-16 20:17:14.115619  \\\n",
            "0                                   0.0                                   0.0   \n",
            "1                                   0.0                                   0.0   \n",
            "2                                   0.0                                   0.0   \n",
            "3                                   0.0                                   0.0   \n",
            "4                                   0.0                                   0.0   \n",
            "\n",
            "   Hire_Date_2025-07-20 20:17:14.115619  Hire_Date_2025-07-23 20:17:14.115619  \n",
            "0                                   0.0                                   0.0  \n",
            "1                                   0.0                                   0.0  \n",
            "2                                   0.0                                   0.0  \n",
            "3                                   0.0                                   0.0  \n",
            "4                                   0.0                                   0.0  \n",
            "\n",
            "[5 rows x 1952 columns]\n"
          ]
        }
      ],
      "source": [
        "# ==============================\n",
        "# Step 1: Import Libraries\n",
        "# ==============================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# ==============================\n",
        "# Step 2: Load Dataset\n",
        "# ==============================\n",
        "# Upload your dataset in Colab, or directly use the file path if available\n",
        "df = pd.read_csv(\"synthetic_employee_data.csv\")\n",
        "\n",
        "# View basic info\n",
        "print(\"Dataset Shape:\", df.shape)\n",
        "print(\"\\nPreview of dataset:\\n\", df.head())\n",
        "print(\"\\nMissing values count:\\n\", df.isnull().sum())\n",
        "print(\"\\nData types:\\n\", df.dtypes)\n",
        "\n",
        "# ==============================\n",
        "# Step 3: Handle Missing Values\n",
        "# ==============================\n",
        "# Separate categorical and numerical columns\n",
        "num_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
        "cat_cols = df.select_dtypes(include=['object']).columns\n",
        "\n",
        "print(\"\\nNumerical columns:\", list(num_cols))\n",
        "print(\"Categorical columns:\", list(cat_cols))\n",
        "\n",
        "# Imputer for missing values\n",
        "num_imputer = SimpleImputer(strategy=\"mean\")   # replace missing numerical values with mean\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")  # replace missing categorical with most frequent\n",
        "\n",
        "# ==============================\n",
        "# Step 4: Encoding Categorical Variables\n",
        "# ==============================\n",
        "# We'll use OneHotEncoding for categorical features\n",
        "# (If you have high-cardinality features, LabelEncoding could also be used)\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        (\"num\", num_imputer, num_cols),\n",
        "        (\"cat\", Pipeline([\n",
        "            (\"imputer\", cat_imputer),\n",
        "            (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
        "        ]), cat_cols)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ==============================\n",
        "# Step 5: Scaling Numerical Features\n",
        "# ==============================\n",
        "# We'll add StandardScaler for numerical values\n",
        "pipeline = Pipeline(steps=[\n",
        "    (\"preprocessor\", preprocessor),\n",
        "    (\"scaler\", StandardScaler(with_mean=False)) # with_mean=False because sparse data after OneHot\n",
        "])\n",
        "\n",
        "# Apply transformations\n",
        "processed_array = pipeline.fit_transform(df)\n",
        "\n",
        "# Convert back to DataFrame with proper feature names\n",
        "ohe_features = list(pipeline.named_steps[\"preprocessor\"]\n",
        "                    .named_transformers_[\"cat\"]\n",
        "                    .named_steps[\"encoder\"].get_feature_names_out(cat_cols))\n",
        "\n",
        "processed_df = pd.DataFrame(\n",
        "    processed_array.toarray() if hasattr(processed_array, \"toarray\") else processed_array,\n",
        "    columns=list(num_cols) + ohe_features\n",
        ")\n",
        "\n",
        "print(\"\\nProcessed Dataset Shape:\", processed_df.shape)\n",
        "print(\"\\nPreview of processed dataset:\\n\", processed_df.head())\n"
      ]
    }
  ]
}